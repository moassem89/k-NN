{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536e3022-e285-4935-97d8-a3f553b7b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest labels: ['BLUE' 'RED' 'RED']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data = [[[255,0,0],\"RED\"], [[255,51,0],\"RED\"], [[255,102,0],\"RED\"], [[204,0,0],\"RED\"], [[190,0,20],\"RED\"], [[0,0,153],\"BLUE\"], [[0,51,204],\"BLUE\"], [[51,51,255],\"BLUE\"], [[0,102,255], \"BLUE\"], [[204,0,198],\"BLUE\"]]\n",
    "target = np.array([[255,51,120]]) # Must be a 2D array (see explanation below)\n",
    "\n",
    "# Separate features and labels as the fit() method expects feature vectors, not the label-data tuples. \n",
    "features = np.array([item[0] for item in data])\n",
    "labels = np.array([item[1] for item in data])\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=3, metric='euclidean') # Try n_neighbors = 1 or any k. Try metric = 'manhattan'\n",
    "knn.fit(features) # fitting is on features only\n",
    "\n",
    "distances, indices = knn.kneighbors(target)\n",
    "\n",
    "#print(f\"Distances: {distances}\")\n",
    "#print(f\"Indices: {indices}\")\n",
    "print(f\"Nearest labels: {labels[indices[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a390d03-2ef9-4194-89c3-3ad27f7d01a0",
   "metadata": {},
   "source": [
    "If you want direct classification, use KNeighborsClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae0a24d-0089-4e04-b4e7-9730257d88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted color: RED\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_classifier.fit(features, labels)\n",
    "\n",
    "prediction = knn_classifier.predict(target)\n",
    "print(f\"Predicted color: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925a1b0-8563-474e-8987-c3c6e4d71df7",
   "metadata": {},
   "source": [
    "Key characteristics:\n",
    "\n",
    "    Optimized Algorithm: Uses ball trees/kd-trees for O(n log n) searches\n",
    "\n",
    "    Parallel Processing: Automatically uses multiple CPU cores\n",
    "\n",
    "    Distance Metrics: Supports 20+ metrics out-of-the-box\n",
    "\n",
    "    Batch Processing: Can predict multiple targets at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a638f3-5652-4b3d-a7db-1965c5b1db99",
   "metadata": {},
   "source": [
    "**Why target Must Be 2D in scikit-learn**\n",
    "\n",
    "In scikit-learn, all input data must be 2-dimensional arrays where:\n",
    "\n",
    "    Rows represent samples/data points\n",
    "\n",
    "    Columns represent features/attributes\n",
    "\n",
    "This is a core design principle in scikit-learn to maintain consistency across all algorithms. Here's why your target needs to be 2D:\n",
    "\n",
    "1. Consistent Data Representation\n",
    "\n",
    "Scikit-learn treats every input as a collection of samples - even single points:\n",
    "\n",
    "    [255, 51, 120] → 1D array (interpreted as 3 features with unknown samples)\n",
    "\n",
    "    [[255, 51, 120]] → 2D array (1 sample × 3 features)\n",
    "    \n",
    "2. Batch Processing Capability\n",
    "\n",
    "Scikit-learn is optimized for processing multiple samples at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "125940f4-5820-44e7-8633-d8f4cbfb283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest labels: ['BLUE' 'RED' 'RED']\n"
     ]
    }
   ],
   "source": [
    "# Predicting 3 targets simultaneously\n",
    "targets = np.array([\n",
    "    [255, 51, 120],\n",
    "    [0, 0, 153],\n",
    "    [190, 0, 20]\n",
    "])  # Shape: (3 samples, 3 features)\n",
    "\n",
    "distances, indices = knn.kneighbors(targets)\n",
    "\n",
    "print(f\"Nearest labels: {labels[indices[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061f615-0eb6-4cb6-9867-deff3682cd08",
   "metadata": {},
   "source": [
    "For Very Large Datasets add these parameters for better performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1211f318-4782-4b53-ba54-46f3548302e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(\n",
    "    n_neighbors=3,\n",
    "    metric='euclidean',\n",
    "    algorithm='ball_tree',  # or 'kd_tree'\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2d42a-5f2e-4aca-8983-31a938f00696",
   "metadata": {},
   "source": [
    "More to KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaa79234-f65c-4a57-b9fb-25fd10afc4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute-force predictions completed. Nearest neighbors are:  ['RED']\n",
      "k-d tree predictions completed. Nearest neighbors are:  ['RED']\n",
      "Ball Tree predictions completed. Nearest neighbors are:  ['RED']\n"
     ]
    }
   ],
   "source": [
    "# Naive approach (brute-force)\n",
    "knn_brute = KNeighborsClassifier(n_neighbors=3, algorithm='brute')\n",
    "knn_brute.fit(features, labels)\n",
    "brute_predictions = knn_brute.predict(target)\n",
    "print(\"Brute-force predictions completed. Nearest neighbors are: \", brute_predictions)\n",
    "\n",
    "# Using a k-d tree (faster for low dimensions)\n",
    "knn_kd_tree = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')\n",
    "knn_kd_tree.fit(features, labels)\n",
    "kdtree_predictions = knn_kd_tree.predict(target)\n",
    "print(\"k-d tree predictions completed. Nearest neighbors are: \", kdtree_predictions)\n",
    "\n",
    "# Using a Ball Tree (faster for higher dimensions)\n",
    "knn_ball_tree = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree')\n",
    "knn_ball_tree.fit(features, labels)\n",
    "balltree_predictions = knn_ball_tree.predict(target)\n",
    "print(\"Ball Tree predictions completed. Nearest neighbors are: \", balltree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6304f-5612-45c7-910b-835d707fda8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
